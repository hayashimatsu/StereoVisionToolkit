# ğŸ“˜ **StereoVisionToolkit â€” Road Rut Depth Measurement (mm accuracy)**

A complete stereo-vision processing pipeline for **millimeter-level rut depth estimation** using smartphone stereo images or any calibrated stereo camera pair.
This project includes a fully modular architecture, robust rectification for **non-synchronized stereo cameras**, accurate 3D reconstruction, and multi-stage rut-shape extraction.

# ğŸš€ Overview

This toolkit implements an end-to-end geometric vision pipeline:

1. **Stereo Rectification (robust for non-synchronized cameras)**
2. **SGBM-based disparity computation (auto-tuned parameters)**
3. **3D reconstruction using corrected Q matrix**
4. **Rut profile extraction (slope correction, filtering, baseline alignment)**
5. **Final rut depth measurement in millimeters**

The system is designed to be:

* Engineering-accurate
* Modular and extensible
* Suitable for research, road-inspection prototyping, or 3D reconstruction tasks

---

# ğŸ–¼ï¸ Example Input/Output

### **Input Images**
> âš ï¸ Note  
> The photo includes a 1/60â€‘second time lag: the right frame is captured slightly later than the left.

|                                 Left camera                                 |                                 Right camera                                |
| :-------------------------------------------------------------------------: | :-------------------------------------------------------------------------: |
| ![Left](document/image_demo/left_001.jpg) | ![Right](document/image_demo/right_001.jpg) |



### **Rectified Output**
> ğŸ’¡ Tip  
> Use a yellow line to indicate the section selected for rutâ€‘shape calculation.

![Rectified](document/image_demo/rectified_marked_001.jpg)


### **Final Rut Depth Result**

![Rut Profile](document/image_demo/rut_depth_analysis_001.png)

> ğŸ“Š Comparison  
> The result is compared with the LiDAR data. Notice that the bottom position is almost aligned.

![Rut Profile](document/answer/graph.jpg)

---

# ğŸ¯ Key Features

### âœ” **1. Robust Stereo Rectification for Non-Synchronized Cameras**

Standard `cv2.stereoRectify()` assumes synchronized stereo inputs.
Real smartphone captures often violate this assumption due to:

* Time lag between left/right images
* Moving objects on the road
* Camera motion
* Vertical/horizontal parallax
* FOV mismatch

This project implements an enhanced rectification pipeline:

#### Improvements:

* Auto-calculation of minimal bounding box to prevent FOV loss
* Correction of rectification parameters (`alpha`, scaling, ROI)
* Recalculation of projection matrices (P1/P2) with shifted principal points
* Regeneration of Q matrix for metric-accurate reconstruction
* Guaranteed full-frame rectification even with time-lagged pairs

These corrections enable stable disparity estimation and accurate 3D reconstruction.

### âœ” **2. Auto-Tuned SGBM Disparity**

Automatically determines `numDisparities` and SGBM parameters based on:

* baseline
* focal length (pixels)
* expected depth range
* target accuracy

Provides:

* dense disparities
* sub-pixel refinement
* noise suppression for road surfaces

### âœ” **3. Metric-Accurate 3D Reconstruction**

Using the corrected Q matrix, the system produces:

* millimeter-level world coordinates
* ground-plane alignment (XYZ rotation)
* consistent metrics regardless of input resolution

### âœ” **4. Multi-Stage Rut Profile Extraction**

Includes:

* Outlier removal (MAD-based)
* Slope correction
* Baseline normalization
* Optional low-pass filtering
* Final rut depth using geometric intersection

All intermediate results can be saved for debugging or research.

---
# ğŸ”„ **Processing Pipeline**
```
Left/Right Images
Parameter (K1.csv, K2.csv, d1.csv, d2.csv, R.csv, T.csv, left_<case>.json)
        â”‚
        â–¼
[1] Rectification
    â€¢ Undistortion + normalization
    â€¢ Rotation to rectify epipolar lines
    â€¢ Auto-resized bounding box
    â€¢ Adjusted P1/P2 and regenerated Q
        â”‚
        â–¼
[2] Disparity Estimation (SGBM)
    â€¢ Horizontal matching on rectified pair
    â€¢ Auto-calculated disparity range
    â€¢ Sub-pixel refinement
        â”‚
        â–¼
[3] 3D Reconstruction
    â€¢ Reproject disparity â†’ (X,Y,Z) using corrected Q
    â€¢ Convert camera coords â†’ road coords
    â€¢ Produce metric-accurate depth/point cloud
        â”‚
        â–¼
[4] Rut Profile Extraction
    â€¢ Sample 3D points along seed-defined line
    â€¢ Remove outliers & correct slope
    â€¢ Normalize height & smooth profile
    â€¢ Compute rut depth (mm)
        â”‚
        â–¼
Final Output (Rut Depth, mm)

```

---

# ğŸ“š Additional Documentation (Theory & Details)

If you want deeper explanation of algorithms and implementation:

### **ğŸ“˜ Program Deep Dive**

* `document/PROJECT_DEEP_DIVE.md`
  Detailed system description, module hierarchy, and full algorithmic explanations.

### **ğŸ“˜ Stereo Camera Theory**

* `document/ã‚¹ãƒ†ãƒ¬ã‚ªã‚«ãƒ¡ãƒ©ã‚’ç”¨ã„ãŸã‚ã ã¡ã¼ã‚Œé‡ã®ç®—å‡º_ç¬¬äºŒç« _2æ¬¡å…ƒåº§æ¨™ã‹ã‚‰3æ¬¡å…ƒåº§æ¨™ã¸ã®å¤‰æ›.docx`
* `document/ã‚¹ãƒ†ãƒ¬ã‚ªã‚«ãƒ¡ãƒ©ã‚’ç”¨ã„ãŸã‚ã ã¡ã¼ã‚Œé‡ã®ç®—å‡º_ç¬¬ä¸‰ç« _ã‚¹ãƒ†ãƒ¬ã‚ªç”»åƒã®å¹³è¡ŒåŒ–å‡¦ç†.docx`

These explain:

* 2D â†’ 3D coordinate transformation
* Rectification geometry

---

# ğŸ“‚ **Repository Structure**

```
StereoVisionToolkit/
â”œâ”€â”€ main.py                          # Entry point, orchestrates the full pipeline

â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.py                    # Configuration loader and validator
â”‚   â”œâ”€â”€ config_rut_shape.json        # Main rut shape configuration
â”‚   â””â”€â”€ config_rut_shape1.json       # Alternative configuration
â”œâ”€â”€ src_rut_shape/
â”‚   â”œâ”€â”€ rut_shape.py                 # High-level rut extraction pipeline
â”‚   â”œâ”€â”€ rectify_refactored.py        # Stage 1: Stereo rectification (improved)
â”‚   â”œâ”€â”€ disparity_refactored.py      # Stage 2: Disparity calculation (SGBM)
â”‚   â”œâ”€â”€ depth.py                     # Stage 3: 3D reconstruction
â”‚   â”œâ”€â”€ height_refactored.py         # Stage 4: Rut shape extraction
â”‚   â”œâ”€â”€ base/
â”‚   â”‚   â”œâ”€â”€ file_manager.py          # File I/O operations
â”‚   â”‚   â””â”€â”€ processor.py             # Template for pipeline processors
â”‚   â”œâ”€â”€ rectification/
â”‚   â”‚   â”œâ”€â”€ engine.py                # Core rectification engine
â”‚   â”‚   â”œâ”€â”€ matrix_calculator.py     # P1/P2/Q matrix correction
â”‚   â”‚   â””â”€â”€ file_manager.py          # Rectification file I/O
â”‚   â”œâ”€â”€ disparity/
â”‚   â”‚   â”œâ”€â”€ sgbm_engine.py           # SGBM computation engine
â”‚   â”‚   â”œâ”€â”€ parameter_calculator.py  # Auto-parameter tuning
â”‚   â”‚   â””â”€â”€ disparity_processor.py   # Post-processing (sub-pixel, filtering)
â”‚   â””â”€â”€ height/
â”‚       â”œâ”€â”€ processors.py            # Profile filtering, slope correction
â”‚       â”œâ”€â”€ rut_calculator.py        # Final rut depth estimation
â”‚       â”œâ”€â”€ image_loader.py          # Image and data loader
â”‚       â”œâ”€â”€ coordinate_processor.py  # Coordinate frame alignment (XYZ rotation)
â”‚       â””â”€â”€ file_manager.py          # File operations for height stage
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ point_processor.py           # Geometric utilities
â”‚   â”œâ”€â”€ image_processing.py          # Image manipulation helpers
â”‚   â”œâ”€â”€ low_pass_filter.py           # Signal filtering
â”‚   â”œâ”€â”€ data_scaling.py              # Coordinate scaling helpers
â”‚   â”œâ”€â”€ rut_visualization.py         # Rut plotting utilities
â”‚   â”œâ”€â”€ visualizer.py                # Misc visualization
â”‚   â”œâ”€â”€ stereo_math.py               # Stereo geometry calculations
â”‚   â”œâ”€â”€ file_operations.py           # File I/O
â”‚   â””â”€â”€ logger_config.py             # Logging configuration
â””â”€â”€ document/
    â”œâ”€â”€ README.md                    # User guide (this file)
    â”œâ”€â”€ PROJECT_DEEP_DIVE.md         # Technical deep dive
    â””â”€â”€ TECHNOLOGY_TRANSFER.md       # Implementation documentation
```

## ğŸ“¦ Data Conventions

### **Images**

```
data/<dataset>/<case_name>/set_*/<pair_name>/
    left_<pair>.jpg
    right_<pair>.jpg
```

### **Parameters**

Stored under:

```
parameter/<dataset>/<case_name>
```

Required files:

* `K1.csv`, `d1.csv`
* `K2.csv`, `d2.csv`
* `R.csv`, `T.csv`
* `disparityToDepthMap.csv`
* `left_<pair>.json`
  â†’ includes `rut_1`, `rut_2` seed endpoints in the original image

Here is the input example:
```json
{
  "case_name"         : "001",
  "image_set_folder"  : "data/2024_1106/{case_name}",
  "parameter_path"    : "parameter/2024_1106/{case_name}"
}
```
---

# â–¶ How to Run

```
python main.py --config config/config_rut_shape.json
```
All required parameters are defined in the JSON file.

Inputs:

* left/right images
* calibration parameters (K1, K2, d1, d2, R, T)
* seed points for rut-line interpolation

Outputs:

* disparity map
* 3D world coordinates
* rut profile
* final rut depth (mm)

---

# ğŸ§ª Applications

* Road surface inspection
* Infrastructure monitoring
* Stereo depth estimation research
* Smartphone-based 3D measurement
* Geometry-based computer vision experimentation

---
